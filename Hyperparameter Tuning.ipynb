{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Input\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"hp\" object is used as an argument to sample the hyperparameter range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    units = hp.Int(name=\"units\",min_value=16,max_value=64,step=16) # Range of units from 16 to 64\n",
    "    model = Sequential([\n",
    "        Dense(units,activation=\"relu\"),\n",
    "        Dense(10,activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer = hp.Choice(name=\"optimizer\",values=[\"rmsprop\",\"adam\"])\n",
    "    model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More modular approach to build model\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self,num_classes):\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def build(self, hp):\n",
    "        units = hp.Int(name=\"units\",min_value=16,max_value=64,step=16) # Range of units from 16 to 64\n",
    "        model = Sequential([\n",
    "            Dense(units,activation=\"relu\"),\n",
    "            Dense(self.num_classes,activation=\"softmax\")\n",
    "        ])\n",
    "        optimizer = hp.Choice(name=\"optimizer\",values=[\"rmsprop\",\"adam\"])\n",
    "        model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = SimpleMLP(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is to build a tuner(Using Bayesian Optmization here, which attempts to make smart predictions on the new hyper parameter values by looking at the previous choices)\n",
    "\n",
    "tuner = kt.BayesianOptimization(build_model,objective=\"val_accuracy\",max_trials=100,executions_per_trial=2,directory=\"mnist_kt_test\",overwrite=True)\n",
    "\n",
    "# Objective --> Metric that the tuner will seek to optimize\n",
    "# Trials --> Maximum number of different model configurations to try before giving up\n",
    "# Executions per trial --> To reduce metric variance, we can train the same model multiple times and average the results(How many trials to run for each model config)\n",
    "# Directory --> Where to store the search logs\n",
    "# Overwrite --> Whether to overwrite the data in directory to start a new search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "# To get an overview of the search space\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a non deafault metric, give direction=\"max\" for accuracy related , and \"min\" for loss related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 43s]\n",
      "val_accuracy: 0.9726499915122986\n",
      "\n",
      "Best val_accuracy So Far: 0.9763000011444092\n",
      "Total elapsed time: 01h 44m 21s\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((-1,28*28)).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape((-1,28*28)).astype(\"float32\") / 255\n",
    "x_train_full = x_train[:]\n",
    "x_test_full = x_test[:]\n",
    "num_val_samples = 10000\n",
    "x_train,x_val = x_train[:-num_val_samples] , x_train[-num_val_samples:]\n",
    "y_train,y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
    "callbacks_list = [EarlyStopping(monitor=\"val_loss\",patience=5)]\n",
    "tuner.search(x_train,y_train,callbacks=callbacks_list,validation_data = [x_val, y_val],batch_size =128,epochs=100,verbose=2) # Similar to fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 4\n",
    "best_hps = tuner.get_best_hyperparameters(top_n) # To get the list of hyperparameters which we can padd suring model building\n",
    "# best_model = tuner.get_best_models(top_n) # To get the list of best models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we get the best model, since we dont have to change the hyperparameters, we can include the validation data as well in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the last hyperparameter that we need to find : Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epoch(hp):\n",
    "    model = build_model(hp)\n",
    "    callbacks_list = [\n",
    "        EarlyStopping(monitor=\"val_loss\",patience=10) # We give patience as 10(high value since we dont need underfit models)\n",
    "    ]\n",
    "    history = model.fit(x_train,y_train,validation_data=[x_val,y_val],epochs=100,batch_size=128,callbacks=callbacks_list)\n",
    "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1 # To get the epoch where we had the lowest val loss\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    return best_epoch,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((-1,28*28)).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape((-1,28*28)).astype(\"float32\") / 255\n",
    "x_train_full = x_train[:]\n",
    "y_train_full = y_train[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch ,model = get_best_epoch(hp)\n",
    "    model.fit(x_train_full,y_train_full,batch_size=128,epochs=int(best_epoch*1.2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3892 - accuracy: 0.8935 - val_loss: 0.2008 - val_accuracy: 0.9458\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1929 - accuracy: 0.9452 - val_loss: 0.1430 - val_accuracy: 0.9610\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1460 - accuracy: 0.9577 - val_loss: 0.1214 - val_accuracy: 0.9657\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1190 - accuracy: 0.9656 - val_loss: 0.0950 - val_accuracy: 0.9736\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1006 - accuracy: 0.9706 - val_loss: 0.0883 - val_accuracy: 0.9742\n",
      "Epoch 6/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9747 - val_loss: 0.0731 - val_accuracy: 0.9790\n",
      "Epoch 7/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0772 - accuracy: 0.9775 - val_loss: 0.0622 - val_accuracy: 0.9820\n",
      "Epoch 8/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0693 - accuracy: 0.9796 - val_loss: 0.0569 - val_accuracy: 0.9838\n",
      "Epoch 9/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.0491 - val_accuracy: 0.9865\n",
      "Epoch 10/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0573 - accuracy: 0.9837 - val_loss: 0.0445 - val_accuracy: 0.9884\n",
      "Epoch 11/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0522 - accuracy: 0.9852 - val_loss: 0.0392 - val_accuracy: 0.9890\n",
      "Epoch 12/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0479 - accuracy: 0.9861 - val_loss: 0.0384 - val_accuracy: 0.9898\n",
      "Epoch 13/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.9870 - val_loss: 0.0359 - val_accuracy: 0.9902\n",
      "Epoch 14/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.0332 - val_accuracy: 0.9906\n",
      "Epoch 15/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9892 - val_loss: 0.0317 - val_accuracy: 0.9924\n",
      "Epoch 16/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: 0.0267 - val_accuracy: 0.9937\n",
      "Epoch 17/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.0240 - val_accuracy: 0.9941\n",
      "Epoch 18/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.0228 - val_accuracy: 0.9943\n",
      "Epoch 19/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0281 - accuracy: 0.9925 - val_loss: 0.0258 - val_accuracy: 0.9930\n",
      "Epoch 20/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.0244 - val_accuracy: 0.9937\n",
      "Epoch 21/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0182 - val_accuracy: 0.9957\n",
      "Epoch 22/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0192 - val_accuracy: 0.9948\n",
      "Epoch 23/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0169 - val_accuracy: 0.9963\n",
      "Epoch 24/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0152 - val_accuracy: 0.9967\n",
      "Epoch 25/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.0158 - val_accuracy: 0.9960\n",
      "Epoch 26/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.0132 - val_accuracy: 0.9968\n",
      "Epoch 27/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 28/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 29/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9967 - val_loss: 0.0115 - val_accuracy: 0.9971\n",
      "Epoch 30/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0102 - val_accuracy: 0.9979\n",
      "Epoch 31/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 32/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0130 - val_accuracy: 0.9963\n",
      "Epoch 33/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.0075 - val_accuracy: 0.9989\n",
      "Epoch 34/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.0061 - val_accuracy: 0.9989\n",
      "Epoch 35/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
      "Epoch 36/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
      "Epoch 37/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
      "Epoch 38/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0059 - val_accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 40/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 41/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 43/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "Epoch 44/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 0.9997\n",
      "Epoch 45/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
      "Epoch 46/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "Epoch 47/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "Epoch 48/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
      "Epoch 49/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 51/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 52/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 53/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 9.0827e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 9.5605e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 9.0321e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 7.1962e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 5.7846e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 6.4859e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.6209e-04 - accuracy: 0.9999 - val_loss: 7.3432e-04 - val_accuracy: 0.9999\n",
      "Epoch 60/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 8.5435e-04 - accuracy: 0.9999 - val_loss: 6.1435e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.4778e-04 - accuracy: 0.9999 - val_loss: 6.1561e-04 - val_accuracy: 0.9999\n",
      "Epoch 62/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.5928e-04 - accuracy: 0.9999 - val_loss: 5.3264e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.5453e-04 - accuracy: 0.9999 - val_loss: 4.8109e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 5.9713e-04 - accuracy: 0.9999 - val_loss: 3.1194e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.2246e-04 - accuracy: 0.9999 - val_loss: 7.7138e-04 - val_accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 5.4472e-04 - accuracy: 0.9999 - val_loss: 2.8641e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 4.9860e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 68/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.4796e-04 - accuracy: 0.9999 - val_loss: 2.4189e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 3.7789e-04 - accuracy: 1.0000 - val_loss: 1.3096e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.0983e-04 - accuracy: 0.9999 - val_loss: 1.1822e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.1218e-04 - accuracy: 1.0000 - val_loss: 1.1119e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.0035e-04 - accuracy: 1.0000 - val_loss: 2.1503e-04 - val_accuracy: 0.9999\n",
      "Epoch 73/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.7096e-04 - accuracy: 1.0000 - val_loss: 2.8613e-04 - val_accuracy: 0.9999\n",
      "Epoch 74/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 2.3010e-04 - accuracy: 1.0000 - val_loss: 1.4625e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.9927e-04 - accuracy: 1.0000 - val_loss: 9.8693e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.0218e-04 - accuracy: 1.0000 - val_loss: 1.4356e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3351e-04 - accuracy: 1.0000 - val_loss: 7.0266e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.5485e-04 - accuracy: 1.0000 - val_loss: 6.2264e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.3968e-04 - accuracy: 1.0000 - val_loss: 9.9350e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.3621e-04 - accuracy: 1.0000 - val_loss: 1.7520e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.2291e-04 - accuracy: 1.0000 - val_loss: 7.2792e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.5788e-04 - accuracy: 1.0000 - val_loss: 3.4449e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 9.9811e-05 - accuracy: 1.0000 - val_loss: 5.2192e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.4170e-05 - accuracy: 1.0000 - val_loss: 3.9128e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 8.4275e-05 - accuracy: 1.0000 - val_loss: 7.2000e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.4745e-05 - accuracy: 1.0000 - val_loss: 4.1701e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.4706e-05 - accuracy: 1.0000 - val_loss: 4.5756e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.4176e-05 - accuracy: 1.0000 - val_loss: 1.2351e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.2669e-05 - accuracy: 1.0000 - val_loss: 2.6915e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 5.7254e-05 - accuracy: 1.0000 - val_loss: 2.7873e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 5.3470e-05 - accuracy: 1.0000 - val_loss: 1.9181e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.7769e-05 - accuracy: 1.0000 - val_loss: 2.0594e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.1181e-05 - accuracy: 1.0000 - val_loss: 1.2640e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.9123e-05 - accuracy: 1.0000 - val_loss: 8.5684e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 2.6575e-05 - accuracy: 1.0000 - val_loss: 4.1127e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.2612e-05 - accuracy: 1.0000 - val_loss: 9.4985e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 3.8904e-05 - accuracy: 1.0000 - val_loss: 8.8711e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.7458e-05 - accuracy: 1.0000 - val_loss: 1.2799e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.8741e-05 - accuracy: 1.0000 - val_loss: 6.6540e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.6342e-05 - accuracy: 1.0000 - val_loss: 1.2840e-05 - val_accuracy: 1.0000\n",
      "Best epoch: 99\n",
      "Epoch 1/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.7610e-05 - accuracy: 1.0000\n",
      "Epoch 2/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.4358e-05 - accuracy: 1.0000\n",
      "Epoch 3/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.2562e-05 - accuracy: 1.0000\n",
      "Epoch 4/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.0078e-05 - accuracy: 1.0000\n",
      "Epoch 5/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.2289e-05 - accuracy: 1.0000\n",
      "Epoch 6/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.4837e-05 - accuracy: 1.0000\n",
      "Epoch 7/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 9.5259e-06 - accuracy: 1.0000\n",
      "Epoch 8/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 7.8618e-06 - accuracy: 1.0000\n",
      "Epoch 9/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 6.7740e-06 - accuracy: 1.0000\n",
      "Epoch 10/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 5.7034e-06 - accuracy: 1.0000\n",
      "Epoch 11/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 6.5788e-06 - accuracy: 1.0000\n",
      "Epoch 12/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 4.6099e-06 - accuracy: 1.0000\n",
      "Epoch 13/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 6.4901e-06 - accuracy: 1.0000\n",
      "Epoch 14/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.9166e-06 - accuracy: 1.0000\n",
      "Epoch 15/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 3.1420e-06 - accuracy: 1.0000\n",
      "Epoch 16/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.6500e-06 - accuracy: 1.0000\n",
      "Epoch 17/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 3.9184e-06 - accuracy: 1.0000\n",
      "Epoch 18/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.3712e-06 - accuracy: 1.0000\n",
      "Epoch 19/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.2053e-06 - accuracy: 1.0000\n",
      "Epoch 20/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.5102e-06 - accuracy: 1.0000\n",
      "Epoch 21/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.0619e-06 - accuracy: 1.0000\n",
      "Epoch 22/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 9.3031e-07 - accuracy: 1.0000\n",
      "Epoch 23/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.6833e-06 - accuracy: 1.0000\n",
      "Epoch 24/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 6.0016e-07 - accuracy: 1.0000\n",
      "Epoch 25/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1338e-06 - accuracy: 1.0000\n",
      "Epoch 26/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 8.1486e-07 - accuracy: 1.0000\n",
      "Epoch 27/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 3.2793e-07 - accuracy: 1.0000\n",
      "Epoch 28/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.9013e-07 - accuracy: 1.0000\n",
      "Epoch 29/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.9403e-07 - accuracy: 1.0000\n",
      "Epoch 30/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.5920e-07 - accuracy: 1.0000\n",
      "Epoch 31/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.2011e-07 - accuracy: 1.0000\n",
      "Epoch 32/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.0995e-07 - accuracy: 1.0000\n",
      "Epoch 33/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.7899e-08 - accuracy: 1.0000\n",
      "Epoch 34/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.9655e-08 - accuracy: 1.0000\n",
      "Epoch 35/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 5.5154e-08 - accuracy: 1.0000\n",
      "Epoch 36/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.5007e-08 - accuracy: 1.0000\n",
      "Epoch 37/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.2188e-08 - accuracy: 1.0000\n",
      "Epoch 38/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.8928e-08 - accuracy: 1.0000\n",
      "Epoch 39/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.6267e-08 - accuracy: 1.0000\n",
      "Epoch 40/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.4501e-08 - accuracy: 1.0000\n",
      "Epoch 41/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.0400e-08 - accuracy: 1.0000\n",
      "Epoch 42/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 2.8867e-08 - accuracy: 1.0000\n",
      "Epoch 43/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 2.7090e-08 - accuracy: 1.0000\n",
      "Epoch 44/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 2.5481e-08 - accuracy: 1.0000\n",
      "Epoch 45/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.4267e-08 - accuracy: 1.0000\n",
      "Epoch 46/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.2932e-08 - accuracy: 1.0000\n",
      "Epoch 47/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.1986e-08 - accuracy: 1.0000\n",
      "Epoch 48/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.1116e-08 - accuracy: 1.0000\n",
      "Epoch 49/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 2.0488e-08 - accuracy: 1.0000\n",
      "Epoch 50/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.9407e-08 - accuracy: 1.0000\n",
      "Epoch 51/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.8750e-08 - accuracy: 1.0000\n",
      "Epoch 52/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.8080e-08 - accuracy: 1.0000\n",
      "Epoch 53/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.7413e-08 - accuracy: 1.0000\n",
      "Epoch 54/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.6675e-08 - accuracy: 1.0000\n",
      "Epoch 55/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.6332e-08 - accuracy: 1.0000\n",
      "Epoch 56/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.5791e-08 - accuracy: 1.0000\n",
      "Epoch 57/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.5277e-08 - accuracy: 1.0000\n",
      "Epoch 58/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.4822e-08 - accuracy: 1.0000\n",
      "Epoch 59/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.4289e-08 - accuracy: 1.0000\n",
      "Epoch 60/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.3983e-08 - accuracy: 1.0000\n",
      "Epoch 61/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.3630e-08 - accuracy: 1.0000\n",
      "Epoch 62/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.3332e-08 - accuracy: 1.0000\n",
      "Epoch 63/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2885e-08 - accuracy: 1.0000\n",
      "Epoch 64/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.2614e-08 - accuracy: 1.0000\n",
      "Epoch 65/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2398e-08 - accuracy: 1.0000\n",
      "Epoch 66/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2040e-08 - accuracy: 1.0000\n",
      "Epoch 67/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1720e-08 - accuracy: 1.0000\n",
      "Epoch 68/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1639e-08 - accuracy: 1.0000\n",
      "Epoch 69/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1226e-08 - accuracy: 1.0000\n",
      "Epoch 70/118\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1084e-08 - accuracy: 1.0000\n",
      "Epoch 71/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.0842e-08 - accuracy: 1.0000\n",
      "Epoch 72/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0610e-08 - accuracy: 1.0000\n",
      "Epoch 73/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0377e-08 - accuracy: 1.0000\n",
      "Epoch 74/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0260e-08 - accuracy: 1.0000\n",
      "Epoch 75/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0051e-08 - accuracy: 1.0000\n",
      "Epoch 76/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.9222e-09 - accuracy: 1.0000\n",
      "Epoch 77/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.6500e-09 - accuracy: 1.0000\n",
      "Epoch 78/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.4950e-09 - accuracy: 1.0000\n",
      "Epoch 79/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.2804e-09 - accuracy: 1.0000\n",
      "Epoch 80/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.1493e-09 - accuracy: 1.0000\n",
      "Epoch 81/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.0500e-09 - accuracy: 1.0000\n",
      "Epoch 82/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 8.9069e-09 - accuracy: 1.0000\n",
      "Epoch 83/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 8.7361e-09 - accuracy: 1.0000\n",
      "Epoch 84/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 8.6367e-09 - accuracy: 1.0000\n",
      "Epoch 85/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 8.4400e-09 - accuracy: 1.0000\n",
      "Epoch 86/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 8.3983e-09 - accuracy: 1.0000\n",
      "Epoch 87/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 8.2016e-09 - accuracy: 1.0000\n",
      "Epoch 88/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 8.1718e-09 - accuracy: 1.0000\n",
      "Epoch 89/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 8.0585e-09 - accuracy: 1.0000\n",
      "Epoch 90/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.8897e-09 - accuracy: 1.0000\n",
      "Epoch 91/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.8440e-09 - accuracy: 1.0000\n",
      "Epoch 92/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.6652e-09 - accuracy: 1.0000\n",
      "Epoch 93/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.6334e-09 - accuracy: 1.0000\n",
      "Epoch 94/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.5380e-09 - accuracy: 1.0000\n",
      "Epoch 95/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.5559e-09 - accuracy: 1.0000\n",
      "Epoch 96/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.3751e-09 - accuracy: 1.0000\n",
      "Epoch 97/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.2698e-09 - accuracy: 1.0000\n",
      "Epoch 98/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.2837e-09 - accuracy: 1.0000\n",
      "Epoch 99/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.1466e-09 - accuracy: 1.0000\n",
      "Epoch 100/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.0314e-09 - accuracy: 1.0000\n",
      "Epoch 101/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.0612e-09 - accuracy: 1.0000\n",
      "Epoch 102/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.9161e-09 - accuracy: 1.0000\n",
      "Epoch 103/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.9559e-09 - accuracy: 1.0000\n",
      "Epoch 104/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.8068e-09 - accuracy: 1.0000\n",
      "Epoch 105/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.7393e-09 - accuracy: 1.0000\n",
      "Epoch 106/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.6956e-09 - accuracy: 1.0000\n",
      "Epoch 107/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.6062e-09 - accuracy: 1.0000\n",
      "Epoch 108/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.6002e-09 - accuracy: 1.0000\n",
      "Epoch 109/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.4433e-09 - accuracy: 1.0000\n",
      "Epoch 110/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.4294e-09 - accuracy: 1.0000\n",
      "Epoch 111/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.4075e-09 - accuracy: 1.0000\n",
      "Epoch 112/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.4333e-09 - accuracy: 1.0000\n",
      "Epoch 113/118\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.3916e-09 - accuracy: 1.0000\n",
      "Epoch 114/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.2505e-09 - accuracy: 1.0000\n",
      "Epoch 115/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.2545e-09 - accuracy: 1.0000\n",
      "Epoch 116/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.1433e-09 - accuracy: 1.0000\n",
      "Epoch 117/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.1651e-09 - accuracy: 1.0000\n",
      "Epoch 118/118\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.0956e-09 - accuracy: 1.0000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.9736\n",
      "Epoch 1/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3807 - accuracy: 0.8968 - val_loss: 0.2068 - val_accuracy: 0.9428\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2011 - accuracy: 0.9429 - val_loss: 0.1486 - val_accuracy: 0.9593\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1518 - accuracy: 0.9565 - val_loss: 0.1115 - val_accuracy: 0.9704\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1232 - accuracy: 0.9647 - val_loss: 0.0912 - val_accuracy: 0.9753\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1043 - accuracy: 0.9696 - val_loss: 0.0830 - val_accuracy: 0.9775\n",
      "Epoch 6/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0909 - accuracy: 0.9739 - val_loss: 0.0691 - val_accuracy: 0.9791\n",
      "Epoch 7/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9766 - val_loss: 0.0579 - val_accuracy: 0.9824\n",
      "Epoch 8/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9789 - val_loss: 0.0545 - val_accuracy: 0.9830\n",
      "Epoch 9/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.0464 - val_accuracy: 0.9855\n",
      "Epoch 10/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0577 - accuracy: 0.9830 - val_loss: 0.0428 - val_accuracy: 0.9870\n",
      "Epoch 11/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0529 - accuracy: 0.9843 - val_loss: 0.0385 - val_accuracy: 0.9890\n",
      "Epoch 12/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0480 - accuracy: 0.9860 - val_loss: 0.0351 - val_accuracy: 0.9901\n",
      "Epoch 13/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.0343 - val_accuracy: 0.9895\n",
      "Epoch 14/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 0.0296 - val_accuracy: 0.9915\n",
      "Epoch 15/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 0.0243 - val_accuracy: 0.9936\n",
      "Epoch 16/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 0.0260 - val_accuracy: 0.9926\n",
      "Epoch 17/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.0236 - val_accuracy: 0.9944\n",
      "Epoch 18/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.0198 - val_accuracy: 0.9954\n",
      "Epoch 19/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0272 - accuracy: 0.9926 - val_loss: 0.0232 - val_accuracy: 0.9940\n",
      "Epoch 20/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0251 - accuracy: 0.9930 - val_loss: 0.0176 - val_accuracy: 0.9953\n",
      "Epoch 21/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0182 - val_accuracy: 0.9956\n",
      "Epoch 22/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.0167 - val_accuracy: 0.9965\n",
      "Epoch 23/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.0139 - val_accuracy: 0.9969\n",
      "Epoch 24/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.0129 - val_accuracy: 0.9974\n",
      "Epoch 25/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0172 - accuracy: 0.9956 - val_loss: 0.0129 - val_accuracy: 0.9974\n",
      "Epoch 26/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0117 - val_accuracy: 0.9980\n",
      "Epoch 27/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.0101 - val_accuracy: 0.9978\n",
      "Epoch 28/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0108 - val_accuracy: 0.9975\n",
      "Epoch 29/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 30/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0076 - val_accuracy: 0.9988\n",
      "Epoch 31/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0101 - val_accuracy: 0.9976\n",
      "Epoch 32/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0068 - val_accuracy: 0.9988\n",
      "Epoch 33/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.0061 - val_accuracy: 0.9991\n",
      "Epoch 34/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9986\n",
      "Epoch 35/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
      "Epoch 36/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0058 - val_accuracy: 0.9991\n",
      "Epoch 37/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
      "Epoch 38/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 39/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0049 - val_accuracy: 0.9993\n",
      "Epoch 40/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 41/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0027 - val_accuracy: 0.9997\n",
      "Epoch 42/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
      "Epoch 43/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 44/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
      "Epoch 45/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 46/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
      "Epoch 47/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
      "Epoch 48/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 49/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 51/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 53/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 7.7253e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 8.0687e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 9.2263e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 5.8956e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 8.6021e-04 - val_accuracy: 0.9999\n",
      "Epoch 58/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.7908e-04 - accuracy: 0.9998 - val_loss: 6.4705e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 8.0648e-04 - accuracy: 0.9999 - val_loss: 5.5431e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 8.1129e-04 - accuracy: 0.9999 - val_loss: 5.7690e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.2419e-04 - accuracy: 0.9999 - val_loss: 3.7441e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.1616e-04 - accuracy: 0.9999 - val_loss: 2.9630e-04 - val_accuracy: 0.9999\n",
      "Epoch 63/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.0439e-04 - accuracy: 1.0000 - val_loss: 3.3694e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 4.9202e-04 - accuracy: 1.0000 - val_loss: 3.0039e-04 - val_accuracy: 0.9999\n",
      "Epoch 65/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 4.7930e-04 - accuracy: 0.9999 - val_loss: 2.9189e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 4.3343e-04 - accuracy: 0.9999 - val_loss: 3.2932e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 3.4130e-04 - accuracy: 1.0000 - val_loss: 2.2035e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 3.1722e-04 - accuracy: 1.0000 - val_loss: 1.7283e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 3.5713e-04 - accuracy: 0.9999 - val_loss: 1.5317e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.4162e-04 - accuracy: 1.0000 - val_loss: 1.4561e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.9039e-04 - accuracy: 1.0000 - val_loss: 1.4156e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.0789e-04 - accuracy: 1.0000 - val_loss: 9.0625e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.0514e-04 - accuracy: 1.0000 - val_loss: 1.5396e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.0845e-04 - accuracy: 1.0000 - val_loss: 1.3724e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.7391e-04 - accuracy: 1.0000 - val_loss: 5.8219e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 1.6537e-04 - accuracy: 1.0000 - val_loss: 1.7875e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.2570e-04 - accuracy: 1.0000 - val_loss: 8.0636e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2712e-04 - accuracy: 1.0000 - val_loss: 5.2510e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.3773e-04 - accuracy: 1.0000 - val_loss: 7.6200e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.5192e-04 - accuracy: 1.0000 - val_loss: 4.2736e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.2375e-05 - accuracy: 1.0000 - val_loss: 4.8469e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 9.7597e-05 - accuracy: 1.0000 - val_loss: 4.7647e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.5066e-05 - accuracy: 1.0000 - val_loss: 9.6416e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.9776e-05 - accuracy: 1.0000 - val_loss: 3.8371e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 5.6927e-05 - accuracy: 1.0000 - val_loss: 2.5930e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.2438e-05 - accuracy: 1.0000 - val_loss: 4.7708e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.9505e-05 - accuracy: 1.0000 - val_loss: 7.1070e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.6306e-05 - accuracy: 1.0000 - val_loss: 4.5568e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.4085e-05 - accuracy: 1.0000 - val_loss: 1.7656e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 7.6538e-05 - accuracy: 1.0000 - val_loss: 4.5498e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 4.6941e-05 - accuracy: 1.0000 - val_loss: 1.2388e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.7800e-05 - accuracy: 1.0000 - val_loss: 1.8656e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.4099e-05 - accuracy: 1.0000 - val_loss: 3.9658e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.9548e-05 - accuracy: 1.0000 - val_loss: 1.4355e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 2.0519e-05 - accuracy: 1.0000 - val_loss: 1.8497e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.9430e-05 - accuracy: 1.0000 - val_loss: 1.0450e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 5.0624e-05 - accuracy: 1.0000 - val_loss: 5.7259e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.5973e-05 - accuracy: 1.0000 - val_loss: 9.9943e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.6213e-05 - accuracy: 1.0000 - val_loss: 1.2007e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 5.0080e-05 - accuracy: 1.0000 - val_loss: 3.7982e-06 - val_accuracy: 1.0000\n",
      "Best epoch: 100\n",
      "Epoch 1/120\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 9.8013e-06 - accuracy: 1.0000\n",
      "Epoch 2/120\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.0849e-05 - accuracy: 1.0000\n",
      "Epoch 3/120\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 8.1692e-06 - accuracy: 1.0000\n",
      "Epoch 4/120\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 6.3971e-06 - accuracy: 1.0000\n",
      "Epoch 5/120\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 7.0577e-06 - accuracy: 1.0000\n",
      "Epoch 6/120\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 6.3965e-06 - accuracy: 1.0000\n",
      "Epoch 7/120\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 6.3706e-06 - accuracy: 1.0000\n",
      "Epoch 8/120\n",
      "322/469 [===================>..........] - ETA: 0s - loss: 4.9745e-06 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m best_models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hp \u001b[38;5;129;01min\u001b[39;00m best_hps:\n\u001b[1;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_trained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mevaluate(x_test,y_test)\n\u001b[0;32m      5\u001b[0m     best_models\u001b[38;5;241m.\u001b[39mappend(model)\n",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m, in \u001b[0;36mget_best_trained_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_trained_model\u001b[39m(hp):\n\u001b[0;32m      2\u001b[0m     best_epoch ,model \u001b[38;5;241m=\u001b[39m get_best_epoch(hp)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbest_epoch\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\arany\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_models = [] \n",
    "for hp in best_hps:\n",
    "    model = get_best_trained_model(hp)\n",
    "    model.evaluate(x_test,y_test)\n",
    "    best_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full run was taking lots of time on personal GPU, so stopped manually(No code error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
