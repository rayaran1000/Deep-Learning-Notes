{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual connection : Used so that the noise to the input that occurs during back propagation is minimized\n",
    "# We add a residual connection so that the input of the layer is added to the output of the layer( the shape of the output and input should be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x ------> input\n",
    "#residual = x\n",
    "#x = block(x) # block in the layer\n",
    "#x = add([x,residual]) # adding the input and the output of the layer(the output will have the full information of the input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However , in convolutional layers, the shapes of the input and the output is different, if the number of filters is increased or max pooling is introduced\n",
    "# We use a 1 X 1 Conv2D layer with no activation to add the input and the output of the layer (padding = \"same\" required for this)\n",
    "# If max pooling is introduced, then if max pooling = 2 , then next 1X1 conv2D layer will have strides=2 to match the downsampling caused by the max pooling, and then the residual is added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Conv2D,MaxPool2D,add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying residual connections to the convolutional block\n",
    "input_layer = Input(shape=(32,32,3))\n",
    "\n",
    "conv_layer1 = Conv2D(32,3,activation=\"relu\")(input_layer)\n",
    "residual_1 = conv_layer1 # Output of conv_layer 1 , hence input of conv_layer2\n",
    "\n",
    "#Conv block around which we create the residuals\n",
    "#For conv_layer 2 , layer is defined along with max pooling \n",
    "conv_layer2 = Conv2D(64,3,activation=\"relu\",padding=\"same\")(conv_layer1)\n",
    "max_pool1 = MaxPool2D(2,padding=\"same\")(conv_layer2)\n",
    "\n",
    "# residual_2 is the 1X1 layer with no activation(64 is the number of kernels that will be similar to the previous conv layer), strides=2 since max pooling = 2, and its input will be the previous residual(because we are converting the input into the size of the output of the conv layer 2)\n",
    "residual_2 = Conv2D(64,1,strides=2)(residual_1) \n",
    "add_layer = add([max_pool1,residual_2]) # Adding the previous formatted input with the output of the max pool layer i.e the conv block output of conv_layer2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which creates a residual block with 2 convolutional layers and depending on the pooling parameter, it will have strides or not\n",
    "\n",
    "input_layer = Input(shape=(32,32,3))\n",
    "rescale_layer = Rescaling(1./255)(input_layer)\n",
    "\n",
    "def build_residual_block(previous_layer,filters,pool_size=0,pooling=False): # Pooling default value as False\n",
    "    residual = previous_layer\n",
    "    conv_layer1 = Conv2D(filters,3,activation=\"relu\",padding=\"same\")(previous_layer)\n",
    "    conv_layer2 = Conv2D(filters,3,activation=\"relu\",padding=\"same\")(conv_layer1)\n",
    "    if pooling == False:\n",
    "        residual_reshape = Conv2D(filters,1,padding=\"same\")(residual)\n",
    "        add_layer = add([conv_layer2,residual_reshape])\n",
    "        return add_layer\n",
    "    elif pooling==True:\n",
    "        max_pool1 = MaxPool2D(pool_size,padding=\"same\")(conv_layer2)\n",
    "        residual_reshape = Conv2D(filters,1,strides=pool_size)(residual)\n",
    "        add_layer = add([max_pool1,residual_reshape])\n",
    "        return add_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " rescaling_4 (Rescaling)        (None, 32, 32, 3)    0           ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 32, 32, 64)   1792        ['rescaling_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 32, 32, 64)   36928       ['conv2d_59[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, 16, 16, 64)  0           ['conv2d_60[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 16, 16, 64)   256         ['rescaling_4[0][0]']            \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 16, 16, 64)   0           ['max_pooling2d_14[0][0]',       \n",
      "                                                                  'conv2d_61[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 16, 16, 128)  73856       ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 16, 16, 128)  147584      ['conv2d_62[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 16, 16, 128)  8320        ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 16, 16, 128)  0           ['conv2d_63[0][0]',              \n",
      "                                                                  'conv2d_64[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['add_17[0][0]']                 \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            129         ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 268,865\n",
      "Trainable params: 268,865\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res_block1 = build_residual_block(rescale_layer, filters=64, pool_size=2, pooling=True)\n",
    "res_block2 = build_residual_block(res_block1, filters=128, pool_size=2, pooling=False)\n",
    "\n",
    "# Apply Global Average Pooling\n",
    "gap_layer = GlobalAveragePooling2D()(res_block2) # Used as an alternative to flatten() : averages the values of each channel across the spatial dimensions (width and height) of the feature maps, resulting in a single value per channel.\n",
    "\n",
    "# Add a dense layer\n",
    "output_layer = Dense(1, activation='softmax')(gap_layer)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch normalization : Used for normalization of outputs of the convolutional layers\n",
    "# If possible, try to apply normalization before applying activation like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One convolution layer\n",
    "#conv_layer = Conv2D(32,3,use_bias=False)\n",
    "#conv_layer = BatchNormalization()(conv_layer)\n",
    "#conv_layer = Activation(\"relu\")(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always freeze the batch normalization layers before fine tuning a model (otherwise they will keep updating their internal mean and variance\n",
    "# used during normalization, which can interfere with the very small updates applied to surrounding convolutional layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise seperable convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=vVaRhZXovbw  : Follow this link to understand how the depthwise convolution work\n",
    "# Leads to less computation by dividing the input into different feature groups(each channel is 1 feature group) , and the kernels will be \n",
    "# (1 x 1 X number of channels or feature groups) pointwise convolutions, so that each cell of the output matrix will have info about each feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For input layer, number of channels or features groups is 3 for RGB images and 1 for greyscale\n",
    "# For deeper layers, number of channels or feature groups equals to the number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying all the necessery architecture patterns and building a simpler Xception model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import RandomFlip,RandomRotation,RandomZoom , SeparableConv2D,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        RandomFlip(\"horizontal\"),\n",
    "        RandomRotation(0.1),\n",
    "        RandomZoom(0.2)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(180,180,3))\n",
    "\n",
    "data_aug_layer = data_augmentation(input_layer)\n",
    "\n",
    "rescale_layer = Rescaling(1./255)(data_aug_layer)\n",
    "conv_layer1 = Conv2D(filters=32,kernel_size=5,use_bias=False)(rescale_layer) # We start with Conv2D instead of seperable\n",
    "# Reason : Assumption is feature channels should be largely independent to use Seperable Conv2D, but in case of RGB Channels, they are depedent\n",
    "# So, the first layer will be a normal conv2D layer, after that we will be using Seperable Conv2D\n",
    "\n",
    "# For loop to build the convolutional blocks\n",
    "for size in [32,64,128,256,512] : # size variable will increase when the deeper convolutional block layers are build to maintain the pyramid structure\n",
    "    residual_input = conv_layer1\n",
    "\n",
    "    # Applying Batch normalization before applying activation function\n",
    "    batch_norm1 = BatchNormalization()(conv_layer1)\n",
    "    activation1 = Activation(\"relu\")(batch_norm1)\n",
    "    seperable_conv_layer1 = SeparableConv2D(size,kernel_size=3,padding=\"same\",use_bias=False)(activation1)\n",
    "\n",
    "    # Applying Batch normalization before applying activation function\n",
    "    batch_norm2 = BatchNormalization()(seperable_conv_layer1)\n",
    "    activation2 = Activation(\"relu\")(batch_norm2)\n",
    "    seperable_conv_layer2 = SeparableConv2D(size,kernel_size=3,padding=\"same\",use_bias=False)(activation2)\n",
    "\n",
    "    max_pool_layer = MaxPool2D(3,strides=2,padding=\"same\")(seperable_conv_layer2)\n",
    "\n",
    "    residual_output = Conv2D(size,1,strides=2,padding=\"same\",use_bias=False)(residual_input) # Converting the residual input tensor to the output shape of max pool layer\n",
    "    add_layer = add([max_pool_layer,residual_output]) # adding the residual and the output tensor of max pool layer\n",
    "\n",
    "global_avg_layer = GlobalAveragePooling2D()(add_layer) # Used in place of flatten() \n",
    "dropout_layer = Dropout(0.5)(global_avg_layer)\n",
    "output_layer = Dense(1,activation=\"sigmoid\")(dropout_layer)\n",
    "\n",
    "model = Model(inputs=input_layer,outputs=output_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each convolution block composition:\n",
    "1. Residual_input recorded\n",
    "2. 1 Seperable Conv2D layer with batch normalization applied before activation function\n",
    "3. 1 Seperable Conv2D layer with batch normalization applied before activation function\n",
    "4. 1 Max Pooling layer\n",
    "5. Converting the residual_input to a tensor which can be added by the output of the max pooling layer i.e the output of the convolution block\n",
    "6. Adding the residual and the output tensor of max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 180, 180, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 180, 180, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)        (None, 180, 180, 3)  0           ['sequential[2][0]']             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 176, 176, 32  2400        ['rescaling_2[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 176, 176, 32  128        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 176, 176, 32  0           ['batch_normalization_28[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_28 (Separable  (None, 176, 176, 51  16672      ['activation_28[0][0]']          \n",
      " Conv2D)                        2)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 176, 176, 51  2048       ['separable_conv2d_28[0][0]']    \n",
      " ormalization)                  2)                                                                \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 176, 176, 51  0           ['batch_normalization_29[0][0]'] \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " separable_conv2d_29 (Separable  (None, 176, 176, 51  266752     ['activation_29[0][0]']          \n",
      " Conv2D)                        2)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, 88, 88, 512)  0          ['separable_conv2d_29[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 88, 88, 512)  16384       ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 88, 88, 512)  0           ['max_pooling2d_14[0][0]',       \n",
      "                                                                  'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 512)         0           ['add_14[0][0]']                 \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 512)          0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            513         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 304,897\n",
      "Trainable params: 303,809\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model description:\n",
    "\n",
    "Input Layer --> Data Augmentation layer --> Rescaling layer --> Convolution layer --> Seperable Conv2D block with number of filters 32 --> Seperable Conv2D block with number of filters 64 --> Seperable Conv2D block with number of filters 128 --> Seperable Conv2D block with number of filters 256 --> Seperable Conv2D block with number of filters 512 --> Global Average Pooling layer( same functionality as Flatten layer) --> Dropout layer --> Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
