{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling and resizing the inputs\n",
    "X_train = train_images.reshape(train_images.shape[0],28*28)\n",
    "y_train = train_labels\n",
    "\n",
    "X_test = test_images.reshape(test_images.shape[0],28*28)\n",
    "y_test = test_labels\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense , Input, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28*28,))\n",
    "\n",
    "hidden_layer1 = Dense(512,activation=\"relu\")(inputs)\n",
    "hidden_layer1 = Dropout(0.5)(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = Dense(64,activation=\"relu\")(hidden_layer1)\n",
    "\n",
    "outputs = Dense(10,activation=\"softmax\")(hidden_layer2)\n",
    "\n",
    "model = Model(inputs=inputs,outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "from keras.metrics import Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = SparseCategoricalCrossentropy()\n",
    "optimizer = RMSprop()\n",
    "metrics = SparseCategoricalAccuracy()\n",
    "loss_tracking_metric = Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_training(model,train_images,train_labels,num_epochs,batch_size):\n",
    "\n",
    "# Creating a tensorflow dataset where each element corresponds to a pair of an image and its corresponding label.\n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((train_images,train_labels)) \n",
    "    training_dataset = training_dataset.batch(batch_size) # Batching the dataset \n",
    "\n",
    "# Epoch run for each training epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting of Epoch : {epoch}\")\n",
    "        #Iterating in a random batch of inputs\n",
    "        for image_batch,label_batch in training_dataset:\n",
    "            # Forward propogation starts form here\n",
    "            with tf.GradientTape() as tape:  # Used to record the gradients for forward propagation so that we can use it during back propagation\n",
    "                y_pred = model(image_batch)\n",
    "                loss = loss_func(label_batch,y_pred)\n",
    "            \n",
    "            gradients = tape.gradient(loss,model.trainable_weights) # Recoding the gradients of loss wrt to the model trainable weights\n",
    "            optimizer.apply_gradients(zip(gradients,model.trainable_weights)) # Applying the gradients to optimize the trainable weights\n",
    "            metrics.update_state(label_batch,y_pred) # To calculate the accuracy of the epoch\n",
    "\n",
    "        train_accuracy = metrics.result() # Recording the accuracy and displaying the results\n",
    "        print(f\"Accuracy in Epoch {epoch} : {train_accuracy}\")\n",
    "        metrics.reset_states()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting of Epoch : 0\n",
      "Accuracy in Epoch 0 : 0.9247833490371704\n",
      "Starting of Epoch : 1\n",
      "Accuracy in Epoch 1 : 0.9708333611488342\n",
      "Starting of Epoch : 2\n",
      "Accuracy in Epoch 2 : 0.9818166494369507\n",
      "Starting of Epoch : 3\n",
      "Accuracy in Epoch 3 : 0.9874333143234253\n",
      "Starting of Epoch : 4\n",
      "Accuracy in Epoch 4 : 0.991183340549469\n"
     ]
    }
   ],
   "source": [
    "custom_training(model,X_train,y_train,5,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function # Used to run the function faster, but use this once our function is debugged and running fine(can be used in training as well)\n",
    "def custom_evaluation(model,test_images,test_labels):\n",
    "\n",
    "    # Creating a tensorflow dataset where each element corresponds to a pair of an image and its corresponding label.\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_images,test_labels)) \n",
    "    test_dataset = test_dataset.batch(128) # Batching the dataset\n",
    "\n",
    "    for image_batch,label_batch in test_dataset:\n",
    "        y_pred = model(image_batch,training=True)\n",
    "        loss = loss_func(label_batch,y_pred)\n",
    "        metrics.update_state(label_batch,y_pred)\n",
    "\n",
    "    test_accuracy = metrics.result()\n",
    "    print(f\"Accuracy on test set : {test_accuracy}\")\n",
    "    metrics.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set : Tensor(\"Identity:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "history = custom_evaluation(model,X_test,y_test)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
