{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass method to create a model\n",
    "\n",
    "class TicketClassifier(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.concatenate_layer = Concatenate() # Concatenation layer\n",
    "        self.hidden_layer = Dense(units=64,activation=\"relu\") # Hidden layer\n",
    "        self.priority_score_layer = Dense(units=1,activation=\"sigmoid\") # Priority score layer\n",
    "        self.department_classifier_layer = Dense(units=4,activation=\"softmax\") # Department classifier layer\n",
    "        self.difficulty_classifier_layer = Dense(units=3,activation=\"softmax\") # Difficulty classifier layer\n",
    "\n",
    "    def __call__(self, inputs,training=False): # Input will be passed as a dictionary with these key values ( Training parameter is set to true during training and false during inference)\n",
    "        # Always include training parameter if we want to train our model\n",
    "        title_input = inputs[\"title_data\"] \n",
    "        body_input = inputs[\"body_data\"]\n",
    "        tags_input = inputs[\"tags_data\"]\n",
    "\n",
    "        # The training parameter is used in the output layers to determine whether the model is being used for training or for inference \n",
    "        input_concatenated = self.concatenate_layer([title_input, body_input, tags_input]) # Output of the concatenation layer\n",
    "        hidden_layer_output = self.hidden_layer(input_concatenated) # Output of the concatenation layer passed in hidden layer and output calculated for the hidden layer\n",
    "        priority_score_output = self.priority_score_layer(hidden_layer_output,training=training) # Output of the hidden layer passed in priority score layer and output calculated\n",
    "        department_classifier_output = self.department_classifier_layer(hidden_layer_output,training=training) # Output of the hidden layer passed in department classifier layer and output calculated\n",
    "        difficulty_classifier_output = self.difficulty_classifier_layer(hidden_layer_output,training=training) # Output of the difficulty layer passed in difficulty layer and output calculated\n",
    "\n",
    "        return priority_score_output, department_classifier_output, difficulty_classifier_output # The outputs of the final output layers are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TicketClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenate\n",
      "dense\n",
      "dense_1\n",
      "dense_2\n",
      "dense_3\n"
     ]
    }
   ],
   "source": [
    "# Check the layer names of the model\n",
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to decide the output layer units using the input data...like num_departments and num_difficulty classes, we can define them in __init__ like below\n",
    "\n",
    "#class TicketClassifier(keras.Model):\n",
    "\n",
    "#def __init__(self,num_departments,num_difficulties): # The variables are mentioned here\n",
    "#        super().__init__()\n",
    "#        self.concatenate_layer = Concatenate() \n",
    "#        self.hidden_layer = Dense(units=64,activation=\"relu\") \n",
    "#        self.priority_score_layer = Dense(units=1,activation=\"sigmoid\") \n",
    "#        self.department_classifier_layer = Dense(units=num_departments,activation=\"softmax\")  # The variables are used here\n",
    "#        self.difficulty_classifier_layer = Dense(units=num_difficulties,activation=\"softmax\") # The variables are used here\n",
    "\n",
    "#    def __call__(self, inputs): \n",
    "#        title_input = inputs[\"title_data\"] \n",
    "#        body_input = inputs[\"body_data\"]\n",
    "#        tags_input = inputs[\"tags_data\"]\n",
    "\n",
    "#        input_concatenated = self.concatenate_layer([title_input, body_input, tags_input])\n",
    "#        hidden_layer_output = self.hidden_layer(input_concatenated) \n",
    "#        priority_score_output = self.priority_score_layer(hidden_layer_output) \n",
    "#        department_classifier_output = self.department_classifier_layer(hidden_layer_output) \n",
    "#        difficulty_classifier_output = self.difficulty_classifier_layer(hidden_layer_output) \n",
    "\n",
    "#        return priority_score_output, department_classifier_output, difficulty_classifier_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would then have instantiated the model like below:\n",
    "\n",
    "# model = TicketClassifier(num_departments=4,num_difficulties=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_samples = 1500\n",
    "vocabulary_size =10000\n",
    "num_tags = 100\n",
    "department_num = 4\n",
    "difficulty_num = 3\n",
    "\n",
    "title_data = np.random.randint(0,2,size=(num_samples,vocabulary_size)) # lowest value , highest value , size\n",
    "body_data = np.random.randint(0,2,size=(num_samples,vocabulary_size))\n",
    "tags_data = np.random.randint(0,2,size=(num_samples,num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples,1))\n",
    "department_data = np.random.randint(0,2,size=(num_samples,department_num))\n",
    "difficulty_data = np.random.randint(0,2,size=(num_samples,difficulty_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treaining is set to True, because we are going to train the model\n",
    "priority_score , department_class , difficulty_class = model({\"title_data\":title_data,\"body_data\":body_data,\"tags_data\":tags_data},training=True) # Dictionary passed with the key values mentioned in the class model and the input_data we created are the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling and training the model similar to earlier methods\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=['mean_squared_error', 'categorical_crossentropy', 'categorical_crossentropy'],\n",
    "              metrics={'output_1': 'accuracy', \n",
    "                                          'output_2': 'accuracy', \n",
    "                                          'output_3': 'accuracy'}) # If we want to apply similar metrics or similar losses to 2 or more outputs and need to define a dictionary,\n",
    "# use output_1 , output_2 ,3 .... --> not able to rename them so use these itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 2s 20ms/step - loss: 58.5838 - output_1_loss: 0.3123 - output_2_loss: 40.2767 - output_3_loss: 17.9948 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.3350 - output_3_accuracy: 0.4092 - val_loss: 29.9325 - val_output_1_loss: 0.3309 - val_output_2_loss: 17.4962 - val_output_3_loss: 12.1054 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.5700 - val_output_3_accuracy: 0.2600\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 44.0900 - output_1_loss: 0.3170 - output_2_loss: 25.5812 - output_3_loss: 18.1918 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2700 - output_3_accuracy: 0.3442 - val_loss: 47.8721 - val_output_1_loss: 0.3309 - val_output_2_loss: 30.2706 - val_output_3_loss: 17.2705 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.5700 - val_output_3_accuracy: 0.2600\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 54.1009 - output_1_loss: 0.3170 - output_2_loss: 32.4951 - output_3_loss: 21.2888 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2667 - output_3_accuracy: 0.3375 - val_loss: 41.0801 - val_output_1_loss: 0.3309 - val_output_2_loss: 28.4905 - val_output_3_loss: 12.2586 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.0700 - val_output_3_accuracy: 0.6233\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 68.5993 - output_1_loss: 0.3170 - output_2_loss: 39.9618 - output_3_loss: 28.3206 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2592 - output_3_accuracy: 0.3192 - val_loss: 71.6707 - val_output_1_loss: 0.3309 - val_output_2_loss: 31.9683 - val_output_3_loss: 39.3714 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.2200 - val_output_3_accuracy: 0.2600\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 80.8853 - output_1_loss: 0.3170 - output_2_loss: 48.0828 - output_3_loss: 32.4855 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2383 - output_3_accuracy: 0.3067 - val_loss: 110.2759 - val_output_1_loss: 0.3309 - val_output_2_loss: 45.4537 - val_output_3_loss: 64.4913 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.5700 - val_output_3_accuracy: 0.1167\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 89.3416 - output_1_loss: 0.3170 - output_2_loss: 53.2157 - output_3_loss: 35.8089 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2883 - output_3_accuracy: 0.3583 - val_loss: 128.0995 - val_output_1_loss: 0.3309 - val_output_2_loss: 56.6594 - val_output_3_loss: 71.1092 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.5700 - val_output_3_accuracy: 0.2600\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 101.1588 - output_1_loss: 0.3170 - output_2_loss: 59.7097 - output_3_loss: 41.1320 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2742 - output_3_accuracy: 0.3375 - val_loss: 105.4441 - val_output_1_loss: 0.3309 - val_output_2_loss: 27.6433 - val_output_3_loss: 77.4699 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.1333 - val_output_3_accuracy: 0.6233\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 113.1202 - output_1_loss: 0.3170 - output_2_loss: 63.4420 - output_3_loss: 49.3612 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2925 - output_3_accuracy: 0.3292 - val_loss: 125.7399 - val_output_1_loss: 0.3309 - val_output_2_loss: 75.1516 - val_output_3_loss: 50.2573 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.0700 - val_output_3_accuracy: 0.2600\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 136.7077 - output_1_loss: 0.3170 - output_2_loss: 81.0223 - output_3_loss: 55.3684 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2408 - output_3_accuracy: 0.3392 - val_loss: 148.1300 - val_output_1_loss: 0.3309 - val_output_2_loss: 91.1004 - val_output_3_loss: 56.6987 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.5700 - val_output_3_accuracy: 0.1167\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 147.5460 - output_1_loss: 0.3170 - output_2_loss: 86.7336 - output_3_loss: 60.4954 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.2525 - output_3_accuracy: 0.3258 - val_loss: 201.6321 - val_output_1_loss: 0.3309 - val_output_2_loss: 136.4651 - val_output_3_loss: 64.8360 - val_output_1_accuracy: 0.0000e+00 - val_output_2_accuracy: 0.5700 - val_output_3_accuracy: 0.6233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1baa84927a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({\"title_data\": title_data, \"body_data\": body_data, \"tags_data\": tags_data},\n",
    "          [priority_data,department_data,difficulty_data],\n",
    "          epochs=10,\n",
    "          validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
